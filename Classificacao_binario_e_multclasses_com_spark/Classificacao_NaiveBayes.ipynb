{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c64e677e",
   "metadata": {},
   "source": [
    "#  Classificação com NaiveBayes com Spark usando PySpark\n",
    "\n",
    "\n",
    "\n",
    "## Inicializando o PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3ecfeb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Faz a Interafce entre o Spark e o Jupyter Notebook\n",
    "findspark.init()\n",
    "\n",
    "# Inicializando uma Sessão no Spark\n",
    "spark = SparkSession.builder.appName(\"NaiveBayes\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09d23be",
   "metadata": {},
   "source": [
    "### Hiper Parâmetros\n",
    "\n",
    "> + **modelType**: Tipo de modelo. multinomial, bernoulli e gaussian. (Padrão: multinomial\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dcc5fc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Aplicando  Classificação com NaiveBayes no DataSet Churn\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f45af4",
   "metadata": {},
   "source": [
    "### Carregando o Cunjunto de Dados Churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a673a559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de Registros do Dataset: 150\n",
      "+-----------+----------+-----------+----------+-----------+\n",
      "|sepallength|sepalwidth|petallength|petalwidth|class      |\n",
      "+-----------+----------+-----------+----------+-----------+\n",
      "|5.1        |3.5       |1.4        |0.2       |Iris-setosa|\n",
      "|4.9        |3.0       |1.4        |0.2       |Iris-setosa|\n",
      "|4.7        |3.2       |1.3        |0.2       |Iris-setosa|\n",
      "|4.6        |3.1       |1.5        |0.2       |Iris-setosa|\n",
      "|5.0        |3.6       |1.4        |0.2       |Iris-setosa|\n",
      "+-----------+----------+-----------+----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris = spark.read.csv(\"../Material_do_Curso/iris.csv\",\n",
    "                             header=True, inferSchema=True, sep=\",\")\n",
    "print(f\"Quantidade de Registros do Dataset: {iris.count()}\")\n",
    "iris.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a006167",
   "metadata": {},
   "source": [
    "### Escolha das Variáveis Independentes e Dependente para treinamento do Modelo dados do dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3925284",
   "metadata": {},
   "source": [
    "### Importação do Módulo do PySpark Para o Pré-Processamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5bfe6db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RFormula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fba2d42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+\n",
      "|independente     |dependente|\n",
      "+-----------------+----------+\n",
      "|[5.1,3.5,1.4,0.2]|0.0       |\n",
      "|[4.9,3.0,1.4,0.2]|0.0       |\n",
      "|[4.7,3.2,1.3,0.2]|0.0       |\n",
      "|[4.6,3.1,1.5,0.2]|0.0       |\n",
      "|[5.0,3.6,1.4,0.2]|0.0       |\n",
      "+-----------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Colocando os dados no Formato de dataframe do Spark usando o RFormula\n",
    "rformula = RFormula(formula=\"class ~ .\",\n",
    "                    featuresCol=\"independente\",\n",
    "                    labelCol=\"dependente\")\n",
    "\n",
    "iris_rf = rformula.fit(iris).transform(iris)\n",
    "iris_rf.select(\"independente\", \"dependente\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a115d5",
   "metadata": {},
   "source": [
    "### Separando os Dados entre conjunto de Treino e Teste\n",
    "\n",
    "O Conjunto de dados serão separados entre treino e teste, sendo que **80%** será para treinar o modelo e **20%** para testar o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e8ad20c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de Dados de Treino: 121\n",
      "Quantidade de Dados de Teste: 29\n"
     ]
    }
   ],
   "source": [
    "iris_train, iris_test = iris_rf.randomSplit([0.8, 0.2])\n",
    "print(f\"Quantidade de Dados de Treino: {iris_train.count()}\")\n",
    "print(f\"Quantidade de Dados de Teste: {iris_test.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6b5bf6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Importação do Módulo do PySpark Para Criação do Modelo de Classificação com NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "81b15be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01232e6e",
   "metadata": {},
   "source": [
    "#### Instanciando Objeto e criando o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "96d8cdae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Instanciando o objeto LinearRegression\n",
    "obj_nb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\",\n",
    "                    featuresCol=\"independente\", labelCol=\"dependente\")\n",
    "\n",
    "# Criando o Modelo\n",
    "model_nb = obj_nb.fit(iris_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b952849",
   "metadata": {},
   "source": [
    "#### Realizando Presição com o Modelo Criado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "53e70eb2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+--------------------+\n",
      "|dependente|prediction|         probability|       rawPrediction|\n",
      "+----------+----------+--------------------+--------------------+\n",
      "|       0.0|       0.0|[0.68501211319680...|[-11.888659407883...|\n",
      "|       0.0|       0.0|[0.65986989861165...|[-11.764584095230...|\n",
      "|       0.0|       0.0|[0.65080073087098...|[-11.727133339374...|\n",
      "|       1.0|       1.0|[0.10631602380147...|[-17.197535354296...|\n",
      "|       0.0|       0.0|[0.70063580375075...|[-11.244481911778...|\n",
      "+----------+----------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "previsao_test = model_nb.transform(iris_test)\n",
    "previsao_test.select(\"dependente\", \"prediction\", \"probability\", \"rawPrediction\").show(5, truncate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f492374a",
   "metadata": {},
   "source": [
    "### Avaliando o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b6ed9076",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e7443c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.9310344827586207\n"
     ]
    }
   ],
   "source": [
    "avaliar = MulticlassClassificationEvaluator(labelCol=\"dependente\",\n",
    "                                            predictionCol=\"prediction\",\n",
    "                                            metricName=\"accuracy\")\n",
    "\n",
    "acuracia = avaliar.evaluate(previsao_test)\n",
    "\n",
    "print(f\"Acurácia: {acuracia}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064ed76a",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
